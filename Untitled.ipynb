{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01b27912-1fd6-4e52-a94e-238f3fceb984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e2dd193-7016-4715-ba4e-4efe3290685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Make sure 'model' folder exists\n",
    "os.makedirs(\"model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f71f51af-5fed-4a65-9733-fc13f5c669fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cad4c55-6c2c-4dbe-a4b0-6865a1c45894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Check shape and first few rows\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f33f0990-e09e-4a36-a254-72c8495d77a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1600, 20)\n",
      "Test set size: (400, 20)\n"
     ]
    }
   ],
   "source": [
    "# Features (X) and target (y)\n",
    "X = data.drop(\"price_range\", axis=1)\n",
    "y = data[\"price_range\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e79046d4-a8c4-4590-b96d-a6891e9b96a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n",
      "Precision: 0.9751162260148967\n",
      "Recall: 0.9746570910973085\n",
      "F1 Score: 0.9744087955693106\n",
      "MCC: 0.9668750318289149\n",
      "AUC: 0.999592616116934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression with different solver\n",
    "log_reg = LogisticRegression(max_iter=5000, solver=\"saga\", random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "y_proba = log_reg.predict_proba(X_test_scaled)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba, multi_class=\"ovr\"))\n",
    "\n",
    "# Save Logistic Regression model\n",
    "joblib.dump(log_reg, \"model/logistic.pkl\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_log_reg = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred, average=\"macro\"),\n",
    "    \"Recall\": recall_score(y_test, y_pred, average=\"macro\"),\n",
    "    \"F1 Score\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "    \"MCC\": matthews_corrcoef(y_test, y_pred),\n",
    "    \"AUC\": roc_auc_score(y_test, y_proba, multi_class=\"ovr\")\n",
    "}\n",
    "with open(\"model/logistic_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics_log_reg, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0a40058-34a2-4a93-8ab6-9e7beeaa6193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8325\n",
      "Precision: 0.8294209737715853\n",
      "Recall: 0.8271982998885173\n",
      "F1 Score: 0.8267094179840447\n",
      "MCC: 0.7768889113441807\n",
      "AUC: 0.8858106422623003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# Initialize and train Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_proba_dt = dt_model.predict_proba(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_dt, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_dt, average=\"macro\"))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_dt, average=\"macro\"))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred_dt))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba_dt, multi_class=\"ovr\"))\n",
    "\n",
    "joblib.dump(dt_model, \"model/decision_tree.pkl\")\n",
    "with open(\"model/decision_tree_metrics.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_dt),\n",
    "        \"Precision\": precision_score(y_test, y_pred_dt, average=\"macro\"),\n",
    "        \"Recall\": recall_score(y_test, y_pred_dt, average=\"macro\"),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred_dt, average=\"macro\"),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred_dt),\n",
    "        \"AUC\": roc_auc_score(y_test, y_proba_dt, multi_class=\"ovr\")\n",
    "    }, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ea35512-6bce-4182-b954-794bd0427199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9425\n",
      "Precision: 0.9403626000461565\n",
      "Recall: 0.9413904483197961\n",
      "F1 Score: 0.940759081791623\n",
      "MCC: 0.9232607544947808\n",
      "AUC: 0.9902284352635169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# Initialize and train kNN (start with k=5)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "y_proba_knn = knn_model.predict_proba(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_knn, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_knn, average=\"macro\"))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_knn, average=\"macro\"))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred_knn))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba_knn, multi_class=\"ovr\"))\n",
    "\n",
    "joblib.dump(knn_model, \"model/knn.pkl\")\n",
    "with open(\"model/knn_metrics.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_knn),\n",
    "        \"Precision\": precision_score(y_test, y_pred_knn, average=\"macro\"),\n",
    "        \"Recall\": recall_score(y_test, y_pred_knn, average=\"macro\"),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred_knn, average=\"macro\"),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred_knn),\n",
    "        \"AUC\": roc_auc_score(y_test, y_proba_knn, multi_class=\"ovr\")\n",
    "    }, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31b3d401-61ee-49a8-b1b5-0b9aaff353f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7975\n",
      "Precision: 0.7983321971995111\n",
      "Recall: 0.7925799291288422\n",
      "F1 Score: 0.7929277885973955\n",
      "MCC: 0.7313294409200803\n",
      "AUC: 0.9559776739015717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# Initialize and train Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "y_proba_nb = nb_model.predict_proba(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_nb, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_nb, average=\"macro\"))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_nb, average=\"macro\"))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred_nb))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba_nb, multi_class=\"ovr\"))\n",
    "\n",
    "joblib.dump(nb_model, \"model/naive_bayes.pkl\")\n",
    "with open(\"model/naive_bayes_metrics.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_nb),\n",
    "        \"Precision\": precision_score(y_test, y_pred_nb, average=\"macro\"),\n",
    "        \"Recall\": recall_score(y_test, y_pred_nb, average=\"macro\"),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred_nb, average=\"macro\"),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred_nb),\n",
    "        \"AUC\": roc_auc_score(y_test, y_proba_nb, multi_class=\"ovr\")\n",
    "    }, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85244c06-6a6b-48d5-9844-93667f2ff3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8925\n",
      "Precision: 0.8916329841057944\n",
      "Recall: 0.8914183189998408\n",
      "F1 Score: 0.8905478996945861\n",
      "MCC: 0.8571537479912464\n",
      "AUC: 0.9826485414411865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# Initialize and train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_proba_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf, average=\"macro\"))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf, average=\"macro\"))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred_rf))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba_rf, multi_class=\"ovr\"))\n",
    "\n",
    "joblib.dump(rf_model, \"model/random_forest.pkl\")\n",
    "with open(\"model/random_forest_metrics.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_rf),\n",
    "        \"Precision\": precision_score(y_test, y_pred_rf, average=\"macro\"),\n",
    "        \"Recall\": recall_score(y_test, y_pred_rf, average=\"macro\"),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred_rf, average=\"macro\"),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred_rf),\n",
    "        \"AUC\": roc_auc_score(y_test, y_proba_rf, multi_class=\"ovr\")\n",
    "    }, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "696142f0-3759-418e-9020-92f377f9bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905\n",
      "Precision: 0.90258536013253\n",
      "Recall: 0.9045802476508997\n",
      "F1 Score: 0.9029969730791383\n",
      "MCC: 0.873522488115507\n",
      "AUC: 0.9913216801002736\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# Initialize and train XGBoost\n",
    "xgb_model = XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_xgb, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_xgb, average=\"macro\"))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_xgb, average=\"macro\"))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred_xgb))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba_xgb, multi_class=\"ovr\"))\n",
    "\n",
    "joblib.dump(xgb_model, \"model/xgboost.pkl\")\n",
    "with open(\"model/xgboost_metrics.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_xgb),\n",
    "        \"Precision\": precision_score(y_test, y_pred_xgb, average=\"macro\"),\n",
    "        \"Recall\": recall_score(y_test, y_pred_xgb, average=\"macro\"),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred_xgb, average=\"macro\"),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred_xgb),\n",
    "        \"AUC\": roc_auc_score(y_test, y_proba_xgb, multi_class=\"ovr\")\n",
    "    }, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a8f4d89-b155-4627-a242-996005be331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision  Recall  F1 Score     MCC     AUC\n",
      "0  Logistic Regression    0.7575     0.7561  0.7513    0.7531  0.6765  0.9232\n",
      "1        Decision Tree    0.8325     0.8294  0.8272    0.8267  0.7769  0.8858\n",
      "2                  kNN    0.9425     0.9404  0.9414    0.9408  0.9233  0.9902\n",
      "3          Naive Bayes    0.7975     0.7983  0.7926    0.7929  0.7313  0.9560\n",
      "4        Random Forest    0.8925     0.8916  0.8914    0.8905  0.8572  0.9826\n",
      "5              XGBoost    0.9050     0.9026  0.9046    0.9030  0.8735  0.9913\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Collect results into a dictionary\n",
    "results = {\n",
    "    \"Model\": [\"Logistic Regression\", \"Decision Tree\", \"kNN\", \"Naive Bayes\", \"Random Forest\", \"XGBoost\"],\n",
    "    \"Accuracy\": [0.7575, 0.8325, 0.9425, 0.7975, 0.8925, 0.905],\n",
    "    \"Precision\": [0.7561, 0.8294, 0.9404, 0.7983, 0.8916, 0.9026],\n",
    "    \"Recall\": [0.7513, 0.8272, 0.9414, 0.7926, 0.8914, 0.9046],\n",
    "    \"F1 Score\": [0.7531, 0.8267, 0.9408, 0.7929, 0.8905, 0.9030],\n",
    "    \"MCC\": [0.6765, 0.7769, 0.9233, 0.7313, 0.8572, 0.8735],\n",
    "    \"AUC\": [0.9232, 0.8858, 0.9902, 0.9560, 0.9826, 0.9913]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display table\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ff71a-88d8-46e8-bbfa-9e14b28ce579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
